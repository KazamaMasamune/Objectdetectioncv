# Object Detection with Computer Vision ğŸš€

This project uses the **YOLOv8** model to detect and analyze objects (cars ğŸš—, humans ğŸ‘¤, and traffic lights ğŸš¦) in a traffic video. It tracks object movement, determines car behavior (moving or stopped), and counts objects within a defined circular region in the video frames. The output includes an annotated video ğŸ¥ and a CSV file ğŸ“Š with detection data.

## Files ğŸ“‚
- `train.py`: The main Python script for object detection, behavior analysis, and video processing using YOLOv8, OpenCV, NumPy, and pandas ğŸ.
- `trafficobj.mp4`: The input video file used for object detection and analysis ğŸ¬.
- `.gitignore`: Ensures only `train.py` and `trafficobj.mp4` are tracked, ignoring other files in the project directory ğŸ”’.

## Prerequisites âœ…
- Python 3.11 or higher ğŸ
- A virtual environment (recommended) ğŸ› ï¸
- The input video `trafficobj.mp4` (included in the repository) ğŸ“¹
- The YOLOv8 model weights file `yolov8n.pt` (downloaded automatically by the `ultralytics` library or available from the [Ultralytics YOLOv8 repository](https://github.com/ultralytics/ultralytics)) ğŸ¤–

## Setup ğŸ› ï¸
1. **Clone the Repository** ğŸ“¥:
   ```bash
   git clone https://github.com/KazamaMasamune/Objectdetectioncv.git
   cd Objectdetectioncv

   Create and Activate a Virtual Environment (optional but recommended) ğŸŒ:
   python -m venv py311_venv
source py311_venv/bin/activate  # On macOS/Linux ğŸ
# or
py311_venv\Scripts\activate  # On Windows ğŸ–¥ï¸

Install Dependencies ğŸ“¦:
pip install opencv-python numpy pandas ultralytics
Running the Project â–¶ï¸





Ensure train.py and trafficobj.mp4 are in the same directory ğŸ“.



Run the script:

python train.py



Outputs ğŸ‰:





traffic_analyzer_output.mp4: Processed video with bounding boxes, object labels, and counts of objects in the circular region ğŸ¥.



object_detections.csv: CSV file with detection data (frame number, object ID, type, behavior, confidence, coordinates, and whether the object is in the circular region) ğŸ“Š.



Press q while the video window is active to stop processing early ğŸ›‘.

How It Works ğŸ”





Object Detection ğŸ•µï¸: Uses YOLOv8 (yolov8n.pt) to detect cars ğŸš— (COCO class 2), humans ğŸ‘¤ (class 0), and traffic lights ğŸš¦ (class 9) in each video frame.



Behavior Analysis ğŸ“ˆ: For cars, calculates movement distance between frames to classify as "Moving" or "Stopped" (threshold: 5 pixels).



Region Counting ğŸ—ºï¸: Counts objects within a circular region (center: (384, 216), radius: 150 pixels) in the video.



Visualization ğŸ–¼ï¸: Draws bounding boxes, labels (with confidence and behavior), and object counts on the video frames.

Notes ğŸ“





The script assumes the input video is 768x432 pixels. Adjust circle_center and circle_radius in train.py if using a different resolution ğŸ“.



If trafficobj.mp4 is replaced, ensure the new video is compatible with OpenCV ğŸ¬.



The yolov8n.pt model is lightweight but may miss some objects. For better accuracy, consider yolov8m.pt or yolov8l.pt (update the model path in train.py) âš™ï¸.

Future Improvements ğŸŒŸ





Add support for real-time video streams ğŸ“¡.



Implement multi-object tracking for consistent IDs across frames ğŸ”—.



Enhance behavior analysis with speed estimation or direction detection ğŸ§­.

License ğŸ“œ

This project is licensed under the MIT License. See the LICENSE file for details (add a LICENSE file if desired).
